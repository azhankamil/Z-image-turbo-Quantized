# Z-Image-Turbo on GTX 1050 Ti (4GB) â€“ ComfyUI Workflow

This repo shows something simple:

> A 2016 GPU can still generate AI images in 2026.


<img width="1440" height="779" alt="Screenshot 2026-02-27 at 6 45 13â€¯AM" src="https://github.com/user-attachments/assets/697886af-881c-4a2d-8e8d-6b8eb38bd8b7" />

No RTX.  
No 12GB VRAM.  
No fancy AI marketing.  

**Just optimization.**

---

## ğŸ–¥ï¸ Hardware Used

- **GPU:** GTX 1050 Ti (4GB, Pascal â€“ 2016)
- **CPU:** i5-9400F
- **RAM:** 16GB
- **UI:** ComfyUI
- **Model:** Z-Image-Turbo (FP8)

---

## ğŸš€ Whatâ€™s Happening Here?

Modern diffusion models expect big GPUs.

This setup doesnâ€™t have one.

Instead, it works because of:

- **FP8 quantization** â†’ smaller model memory footprint  
- **VRAM â†” RAM offloading** â†’ avoids CUDA OOM crashes  
- **512Ã—512 sweet spot** â†’ manageable activation memory  
- **Lean workflow** â†’ no unnecessary nodes  

### Result

- ~2.4GB loaded on GPU  
- Remaining weights offloaded to RAM  
- Stable image generation on 4GB VRAM  

---

## ğŸ¯ Recommended Settings

| Setting        | Value                         |
|---------------|--------------------------------|
| Resolution     | 512Ã—512                        |
| Steps          | 6â€“8                            |
| Precision      | FP8                            |
| Launch Flags   | `--lowvram --fp8_e4m3fn`        |
| Offloading     | Enabled                        |

> If it crashes:
> - Lower resolution first  
> - Then reduce steps  

---

## ğŸ“¦ Required Models

### 1ï¸âƒ£ Z-Image-Turbo (FP8)

**Place inside:**
ComfyUI/models/diffusion_models/

**File:**
z-image-turbo_fp8_scaled_e4m3fn_KJ.safetensors

---

### 2ï¸âƒ£ Qwen 3 4B (Text Encoder)

**Place inside:**
ComfyUI/models/text_encoders/

**File:**
qwen3_4b_fp8_scaled.safetensors

---

### 3ï¸âƒ£ Flux VAE

**Place inside:**
ComfyUI/models/vae/

**File:**
ae.safetensors

**Optional lightweight VAE:**
vae_approx/

---

## ğŸ“‚ Example Folder Structure
ComfyUI/
â””â”€â”€ models/
â”œâ”€â”€ diffusion_models/
â”‚ â””â”€â”€ z-image-turbo_fp8_scaled_e4m3fn_KJ.safetensors
â”œâ”€â”€ text_encoders/
â”‚ â””â”€â”€ qwen3_4b_fp8_scaled.safetensors
â”œâ”€â”€ vae/
â”‚ â””â”€â”€ ae.safetensors

---

## ğŸ›  How To Use

1. Install ComfyUI  
2. Place models in the correct folders  
3. Launch with:
python main.py --lowvram --fp8_e4m3fn

4. Open:
http://127.0.0.1:8188

5. Drag `workflow.json` into the canvas  
6. Queue your prompt  

**Thatâ€™s it.**
